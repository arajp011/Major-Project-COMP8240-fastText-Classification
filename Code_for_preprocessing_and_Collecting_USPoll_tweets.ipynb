{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Major Project: COMP8240**\n",
    "For this Project, we will use the ariline_sentiment Dataset to train the fastText classifier replacing the original data of stack exchange questions. The project follows the workflow of application of data science project and we will use a facebook's fastText classifier for the classification of collected data from twitter and reddit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the airline_sentiment Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('airline_sentiment.csv')\n",
    "df_check = pd.read_csv('airline_sentiment.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping the data of concern i.e. Tweets, sentiments and Twitter users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['airline_sentiment_confidence']\n",
    "del df['airline_sentiment_gold']\n",
    "del df['negativereason']\n",
    "del df['negativereason_confidence']\n",
    "del df['negativereason_gold']\n",
    "del df['retweet_count']\n",
    "del df['tweet_coord']\n",
    "del df['tweet_created']\n",
    "del df['tweet_id']\n",
    "del df['tweet_location']\n",
    "del df['user_timezone']\n",
    "del df['airline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here comes the part of cleaning up the tweets before training the model on the airline_dataset. Because we want to replicate the original work of experiments, the data has to be of similar quality as of original data only the data annotations are changed to positive, negative an neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "    return input_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above funtion evaluates pyfunc over successive rows of the input arrays using the broadcasting rule of numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = np.vectorize(remove_pattern)(df['text'], \"@[\\w]*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = np.vectorize(remove_pattern)(df['text'], \"#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "nltk_stopwords = stopwords.words('english')\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tweets = 14639\n",
    "corpus = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To clean up the tweets we converted the tweet's text to lowercase, removed @ and Hashtags, removed website urls, removed special characters, removed white spaces, removed emojis/smileys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, max_tweets):\n",
    "    tweet = re.sub(r'(.*?)http.*?\\s?(.*?)', '',\n",
    "            df['text'][i], flags = re.MULTILINE)\n",
    "    tweet = re.sub('[^a-zA-Z0-9]', ' ', tweet)\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub('rt', '', tweet)\n",
    "    tweet = tweet.split()\n",
    "    ps = PorterStemmer()\n",
    "    tweet = [ps.stem(word) for word in tweet\n",
    "        if not word in set(stopwords.words('english'))]\n",
    "    if tweet == []: continue\n",
    "    else:\n",
    "        tweet = ' '.join(tweet)\n",
    "        corpus.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text']=df['text'].apply(lambda row:re.sub(r'http\\S+', '',row))\n",
    "df['text']=df['text'].apply(lambda row : row.lower())\n",
    "df['text']=df['text'].apply(lambda row : re.sub('\\d+','',row))\n",
    "df['text']=df['text'].apply(lambda row:re.sub(r\"[^A-Za-z0-9']+\", ' ',row))\n",
    "df['text']=df['text'].apply(lambda row:re.sub(r'\\s+', ' ',row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the comparison between a random original tweet and cleaned tweet see below :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' your airline is awesome but your lax loft needs to step up its game for dirty tables and floors '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[73].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@VirginAmerica your airline is awesome but your lax loft needs to step up its game. $40 for dirty tables and floors? http://t.co/hy0VrfhjHt'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_check.iloc[73].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formatting the data to be read by fastText classifier. Labels must start by the prefix _label_ which is how fasttext recognizes what a label or what a word is. Csv is then futher converted into to a txt file which is then fed into the fastText training model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['airline_sentiment'] = '__label__' + df['airline_sentiment'].astype(str)\n",
    "df['lableled']=df['airline_sentiment'].astype(str) +' '+ df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['airline_sentiment']\n",
    "del df['text']\n",
    "del df['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lableled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__neutral  what said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__positive  plus you've added commercia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__neutral  i didn't today must mean i n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__negative  it's really aggressive to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__negative  and it's a really big bad t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            lableled\n",
       "0                       __label__neutral  what said \n",
       "1  __label__positive  plus you've added commercia...\n",
       "2  __label__neutral  i didn't today must mean i n...\n",
       "3  __label__negative  it's really aggressive to b...\n",
       "4  __label__negative  and it's a really big bad t..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('airline_labelled.csv', index = False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input csv file name airline_labelled.csv\n",
      "Input text file nameairline_training.txt\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "csv_file = input('Input csv file name ')\n",
    "txt_file = input('Input text file name')\n",
    "with open(txt_file, \"w\") as my_output_file:\n",
    "    with open(csv_file, \"r\") as my_input_file:\n",
    "        [ my_output_file.write(\" \".join(row)+'\\n') for row in csv.reader(my_input_file)]\n",
    "    my_output_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construction of new dataset using Tweepy a python library for accessing Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = '8nJfxRD8HMRNPAjy1PqWX89cI'\n",
    "consumer_key_secret = 'EQJEvLUisoH5DIAFBXZFqI4Du4QMMWIT7BGfsMx9D9s41fh2dI'\n",
    "access_token = '1251336102285242369-evdUh0gDQzpkw6yXJTSQBBEajfzlIS'\n",
    "access_token_secret = '8AJkJnuAMi97jNASBan7GsQi7flZM6c5HFvIcIZbx8fi2'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_key_secret)\n",
    "\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since my goal was to provide frame an opinion on 2020 US presidential elections. I have pulled tweets from the twitter handle â€˜US Politics Pollsâ€™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tweets = 200\n",
    "screen_name = 'USPoliticsPoll'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = api.user_timeline(screen_name = screen_name,\n",
    "                            tweet_mode = 'extended',\n",
    "                            count = max_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below writes tweets to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dicts = []\n",
    "for json_tweet in tweets:\n",
    "    list_of_dicts.append(json_tweet._json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tweet_json_data.txt', mode = 'w') as file:\n",
    "    file.write(json.dumps(list_of_dicts, indent = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading Tweets from the file generated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []\n",
    "with open('tweet_json_data.txt', encoding='utf-8', mode = 'r') as file:\n",
    "    list_of_dicts = json.load(file)\n",
    "    for dict in list_of_dicts:\n",
    "    # Note we read selected information from the tweets.\n",
    "        list.append({'tweet_id': str(dict['id']),\n",
    "                'full_text': str(dict['full_text']),\n",
    "                'favorite_count': int(dict['favorite_count']),\n",
    "                'retweet_count': int(dict['retweet_count']),\n",
    "                'created_at': dict['created_at'],\n",
    "                })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating a dataframe using Tweets Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_new = pd.DataFrame(list, columns = ['tweet_id',\n",
    "                                    'full_text',\n",
    "                                    'favorite_count',\n",
    "                                    'retweet_count',\n",
    "                                    'created_at'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping the data of concern i.e. Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_new['created_at']\n",
    "del df_new['favorite_count']\n",
    "del df_new['tweet_id']\n",
    "del df_new['retweet_count']\n",
    "df_new.rename(columns={'full_text': 'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ðŸ˜­ Good night everyone https://t.co/STrDTOECl8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MARICOPA DUMP NOW https://t.co/57nndQJWMl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clap if you care https://t.co/qdwzFNeuhY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@jarriae @CooperCodes We know that but WSJ see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@CooperCodes When did they call it?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>We were telling yâ€™all about this hours ago ðŸŒš h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Yes, he is https://t.co/4fUgrDPU8Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Pennsylvania, 85% in:\\nTrump 51.6%\\nBiden 47.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Georgia, 94% in:\\nTrump 50.0%\\nBiden 48.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>RT @USPoliticsPoll: Thereâ€™s been a disproporti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0        ðŸ˜­ Good night everyone https://t.co/STrDTOECl8\n",
       "1            MARICOPA DUMP NOW https://t.co/57nndQJWMl\n",
       "2             Clap if you care https://t.co/qdwzFNeuhY\n",
       "3    @jarriae @CooperCodes We know that but WSJ see...\n",
       "4                  @CooperCodes When did they call it?\n",
       "..                                                 ...\n",
       "195  We were telling yâ€™all about this hours ago ðŸŒš h...\n",
       "196                 Yes, he is https://t.co/4fUgrDPU8Q\n",
       "197    Pennsylvania, 85% in:\\nTrump 51.6%\\nBiden 47.1%\n",
       "198         Georgia, 94% in:\\nTrump 50.0%\\nBiden 48.8%\n",
       "199  RT @USPoliticsPoll: Thereâ€™s been a disproporti...\n",
       "\n",
       "[200 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a Csv of the raw tweets to get human annotations using Qualtrics survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv('Polls.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now cleaning up of the tweets and make them machine understandable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_patterns(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "    return input_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['text'] = np.vectorize(remove_patterns)(df_new['text'], \"@[\\w]*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['text'] = np.vectorize(remove_patterns)(df_new['text'], \"#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of cleaning is replicated as is done with the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tweets = 200\n",
    "corpus = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, max_tweets):\n",
    "    tweet = re.sub(r'(.*?)http.*?\\s?(.*?)', '',\n",
    "            df_new['text'][i], flags = re.MULTILINE)\n",
    "    tweet = re.sub('[^a-zA-Z0-9]', ' ', tweet)\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub('rt', '', tweet)\n",
    "    tweet = tweet.split()\n",
    "    ps = PorterStemmer()\n",
    "    tweet = [ps.stem(word) for word in tweet\n",
    "        if not word in set(stopwords.words('english'))]\n",
    "    if tweet == []: continue\n",
    "    else:\n",
    "        tweet = ' '.join(tweet)\n",
    "        corpus.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['text']=df_new['text'].apply(lambda row:re.sub(r'http\\S+', '',row))\n",
    "df_new['text']=df_new['text'].apply(lambda row : row.lower())\n",
    "df_new['text']=df_new['text'].apply(lambda row : re.sub('\\d+','',row))\n",
    "df_new['text']=df_new['text'].apply(lambda row:re.sub(r\"[^A-Za-z0-9']+\", ' ',row))\n",
    "df_new['text']=df_new['text'].apply(lambda row:re.sub(r'\\s+', ' ',row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv('Polls.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we import the annotated new data and convert them into fastText readable form so that we can test our model over them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('Polls_sen.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['label'] = '__label__' + df1['sentiment'].astype(str)\n",
    "df1['lableled']=df1['label'].astype(str) +' '+ df1['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df1['sentiment']\n",
    "del df1['text']\n",
    "del df1['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('Polls1.csv', index = False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lableled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__positive  good night everyone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__negative maricopa dump now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__positive clap if you care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__neutral  we know that but wsj seems new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__neutral  when did they call it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>__label__neutral we were telling y all about t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>__label__positive yes he is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>__label__neutral pennsylvania in trump biden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>__label__neutral georgia in trump biden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>__label__negative rt there s been a disproport...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lableled\n",
       "0              __label__positive  good night everyone \n",
       "1                 __label__negative maricopa dump now \n",
       "2                  __label__positive clap if you care \n",
       "3     __label__neutral  we know that but wsj seems new\n",
       "4             __label__neutral  when did they call it \n",
       "..                                                 ...\n",
       "195  __label__neutral we were telling y all about t...\n",
       "196                       __label__positive yes he is \n",
       "197      __label__neutral pennsylvania in trump biden \n",
       "198           __label__neutral georgia in trump biden \n",
       "199  __label__negative rt there s been a disproport...\n",
       "\n",
       "[200 rows x 1 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input csv file Polls1.csv Polls1.csv \n",
      "Input text file Polls1.txtPolls1.txt\n"
     ]
    }
   ],
   "source": [
    "csv_file = input('Input csv file Polls1.csv ')\n",
    "txt_file = input('Input text file Polls1.txt')\n",
    "with open(txt_file, \"w\") as my_output_file:\n",
    "    with open(csv_file, \"r\") as my_input_file:\n",
    "        [ my_output_file.write(\" \".join(row)+'\\n') for row in csv.reader(my_input_file)]\n",
    "    my_output_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
